{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in this notebook we will test and evaluate models before integrating the pipeline. \n",
    "# @author : Mohamed El Baha\n",
    "# Banknote dataset => classif = 'class'\n",
    "# Kindey dataset => classif = 'classification'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import helper_functions as hf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------\n",
      "                MACHINE LEARNING CLASSIFICATION PIPELINE                 \n",
      "-------------------------------------------------------------------------\n",
      "✓ The kidney data set succefuly imported !\n",
      " ✓ Data succefuly pre-prossesed \n",
      " ✓ Data dimension successfuly reduced\n",
      "\n",
      "Shape of Data \n",
      " Training Data = (280, 20)   | Test Data = (120, 20) \n",
      " Training Labels = (280,)   |  Test_labels = (120,) \n",
      " \n"
     ]
    }
   ],
   "source": [
    "#-------- PLEASE DO NOT MODIFY THE CODE ----------------\n",
    "#\n",
    "#-------------------------------------------------------\n",
    "#                   Import Data   \n",
    "#-------------------------------------------------------\n",
    "# Choose the data set by typing it's name :\n",
    "# The banknote data set please enter ==> 'banknote'\n",
    "# The kidney diseas data set please enter ==> 'kidney'\n",
    "print('-------------------------------------------------------------------------')\n",
    "print('                MACHINE LEARNING CLASSIFICATION PIPELINE                 ')\n",
    "print('-------------------------------------------------------------------------')\n",
    "\n",
    "#print(\"Please enter the name of the Dataset. \\n for the banknote data set please enter ==> banknote \\n for the kidney diseas data set please enter ==> kidney \")\n",
    "name = input(\"Enter here name of the dataset = \")\n",
    "df = hf.import_dataset(name)\n",
    "print(f'✓ The {name} data set succefuly imported !')\n",
    "\n",
    "#-------------------------------------------------------\n",
    "#       Preprocess Data ( clean and normalize data)\n",
    "#-------------------------------------------------------\n",
    "df, y = hf.preprocess_data(df,classif='classification')\n",
    "print(\" ✓ Data succefuly pre-prossesed \")\n",
    "\n",
    "#-------------------------------------------------------\n",
    "#                  Feature Selection\n",
    "# ------------------------------------------------------\n",
    "df = hf.feature_selection(df,'PCA',variance_threshold=0.95)\n",
    "\n",
    "#-------------------------------------------------------\n",
    "#           Split Data ( 70% train, 30% test )\n",
    "#-------------------------------------------------------\n",
    "X_train, X_test, y_train, y_test = hf.split_data(df,y,test_size=0.3)\n",
    "# Explore data shapes \n",
    "X_train.shape\n",
    "X_test.shape \n",
    "print(f'\\nShape of Data \\n Training Data = {X_train.shape}   | Test Data = {X_test.shape} \\n Training Labels = {y_train.shape}   |  Test_labels = {y_test.shape} \\n ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 1 - Logistic Regression => lr \n",
      " 2 - SGD Classifier => sgd_clf \n",
      " 3 - Decision Tree Classifier => dt_clf \n",
      " 4 - AdaBoost Classifier = adab_clf \n",
      " 5 - Random Forset Classifier = rf_clf\n"
     ]
    }
   ],
   "source": [
    "#-------------------------------------------\n",
    "#               Model Selection\n",
    "#-------------------------------------------\n",
    "print('\\n 1 - Logistic Regression => lr \\n 2 - SGD Classifier => sgd_clf \\n 3 - Decision Tree Classifier => dt_clf \\n 4 - AdaBoost Classifier = adab_clf \\n 5 - Random Forset Classifier = rf_clf')\n",
    "model_name = input(\"Please Enter Name of the selected model : \")\n",
    "model,train_score = hf.train_model(model_name,X_train,y_train)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5af6db1fe6810fe648d3ea165c1ad2705eba3129b5b7b03805b160185b3319d3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
