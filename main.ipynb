{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in this notebook we will test and evaluate models before integrating the pipeline. \n",
    "# @author : Mohamed El Baha\n",
    "# Banknote dataset => classif = 'class'\n",
    "# Kindey dataset => classif = 'classification'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import helper_functions as hf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------- Machine Learning Classification Pipeline ----------------\n",
      " ✓ The Banknote data set succefuly imported !\n",
      " ✓ Data succefuly pre-prossesed \n",
      "Feature Selection ==> Principal Component Analysis\n",
      "Number of features selected : 3\n",
      " ✓ Data dimension successfuly reduced\n",
      "Shape of Data \n",
      " Training Data = (960, 3)   | Test Data = (412, 3) \n",
      " Training Labels = (960,)   |  Test_labels = (412,) \n",
      " \n"
     ]
    }
   ],
   "source": [
    "# 1. Import Data\n",
    "# Choose the data set by typing it's name, data sets available are the banknote data set and kidney disease data set :\n",
    "# for the banknote data set please enter ==> 'banknote'\n",
    "# for the kidney diseas data set please enter ==> 'kidney'\n",
    "print('---------------- Machine Learning Classification Pipeline ----------------')\n",
    "#print(\"Please enter the name of the Dataset. \\n for the banknote data set please enter ==> banknote \\n for the kidney diseas data set please enter ==> kidney \")\n",
    "name = input(\"Enter here name of the dataset = \")\n",
    "df = hf.import_dataset(name)\n",
    "print(\" ✓ The Banknote data set succefuly imported !\")\n",
    "# 2. Preprocess Data ( clean and normalize data)\n",
    "df = hf.normalize_data(df)\n",
    "print(\" ✓ Data succefuly pre-prossesed \")\n",
    "\n",
    "# 3. Feature Selection  \n",
    "df = hf.feature_selection(df,'PCA',variance_threshold=0.95)\n",
    "\n",
    "# 4. Split Data ( 70% train, 30% test )\n",
    "X = df.drop(columns=['class '])\n",
    "y = df['class ']\n",
    "X_train, X_test, y_train, y_test = hf.split_data(X,y,test_size=0.3)\n",
    "\n",
    "# Explore data shapes \n",
    "X_train.shape\n",
    "X_test.shape \n",
    "print(f'Shape of Data \\n Training Data = {X_train.shape}   | Test Data = {X_test.shape} \\n Training Labels = {y_train.shape}   |  Test_labels = {y_test.shape} \\n ')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Models = {'SVC':{'model':SVC, #Support vector Classifier\n",
    "                      'parameters':{'kernel':['linear', 'rbf', 'sigmoid', 'poly'], \n",
    "                                                'C'     :[1, 10], \n",
    "                                                'degree': [2, 3],\n",
    "                                                'gamma' : ['scale', 'auto']\n",
    "                                   }\n",
    "                     },\n",
    "               'LogisticRegression':{'model':LogisticRegression, # Logistic Regression\n",
    "                                    'parameters':{'C':[1, 10], \n",
    "                                                'fit_intercept' : [True,False],\n",
    "                                                'intercept_scaling' : [1,10],\n",
    "                                                 }\n",
    "                                    },\n",
    "                'SGDClassifier':{'model':SGDClassifier, # Stochastic gradient descent classifier\n",
    "                                    'parameters':{'loss':['hinge', 'log', 'modified_huber', 'squared_hinge', 'perceptron'], \n",
    "                                                'penalty':['l1', 'l2'], \n",
    "                                                'fit_intercept' : [True,False],\n",
    "                                                 }\n",
    "                                    },\n",
    "                'DecisionTreeClassifier':{'model':RandomForestClassifier,\n",
    "                                    'parameters':{'criterion':['gini', 'entropy'], \n",
    "                                                'max_depth' : [2,5,10,None],\n",
    "                                                 }\n",
    "                                    },\n",
    "                 'AdaBoostClassifier':{'model':AdaBoostClassifier,\n",
    "                                    'parameters':{'n_estimators':[50, 100, 150], \n",
    "                                                'algorithm':['SAMME', 'SAMME.R'], \n",
    "                                                'learning_rate' : [0.1,0.5,1]\n",
    "                                                 }\n",
    "                                    },\n",
    "                 'RandomForestClassifier':{'model':RandomForestClassifier,\n",
    "                                    'parameters':{'n_estimators':[50, 100, 150], \n",
    "                                                'criterion':['gini', 'entropy'], \n",
    "                                                'max_depth' : [2,5,10,None],\n",
    "                                                'bootstrap' : [True,False],\n",
    "                                                 }\n",
    "                                    }\n",
    "                }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Models['AdaBoostClassifier']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = model['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5af6db1fe6810fe648d3ea165c1ad2705eba3129b5b7b03805b160185b3319d3"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
