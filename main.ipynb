{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in this notebook we will test and evaluate models before integrating the pipeline. \n",
    "# @author : Mohamed El Baha\n",
    "# Banknote dataset => classif = 'class'\n",
    "# Kindey dataset => classif = 'classification'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import helper_functions as hf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Data Choosing and Processing\n",
    "\n",
    "   The user can choose between two datasets (kidney and banknote). They'll also need to specify the <b>class</b> parameter (name of the ground-truth column). The data is then preprocessed, feature selection is applied and then divided into two sets for testing and training purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------\n",
      "                MACHINE LEARNING CLASSIFICATION PIPELINE                 \n",
      "-------------------------------------------------------------------------\n",
      "Enter here name of the dataset = kidney\n",
      "✓ The kidney data set successfully imported !\n",
      "Enter here name of the ground-truth column = classification\n",
      " ✓ Data succefuly pre-prossesed \n",
      " ✓ Data dimension successfuly reduced\n",
      "\n",
      "Shape of Data \n",
      " Training Data = (240, 20)   | Test Data = (160, 20) \n",
      " Training Labels = (240, 1)   |  Test_labels = (160, 1) \n",
      " \n"
     ]
    }
   ],
   "source": [
    "#-------- PLEASE DO NOT MODIFY THE CODE ----------------\n",
    "#\n",
    "#-------------------------------------------------------\n",
    "#                   Import Data   \n",
    "#-------------------------------------------------------\n",
    "# Choose the data set by typing it's name :\n",
    "# The banknote data set please enter ==> 'banknote'\n",
    "# The kidney diseas data set please enter ==> 'kidney'\n",
    "print('-------------------------------------------------------------------------')\n",
    "print('                MACHINE LEARNING CLASSIFICATION PIPELINE                 ')\n",
    "print('-------------------------------------------------------------------------')\n",
    "\n",
    "#print(\"Please enter the name of the Dataset. \\n for the banknote data set please enter ==> banknote \\n for the kidney diseas data set please enter ==> kidney \")\n",
    "name = input(\"Enter here name of the dataset = \")\n",
    "df = hf.import_dataset(name)\n",
    "print(f'✓ The {name} data set successfully imported !')\n",
    "\n",
    "#-------------------------------------------------------\n",
    "#       Preprocess Data ( clean and normalize data)\n",
    "#-------------------------------------------------------\n",
    "classif = input(\"Enter here name of the ground-truth column = \")\n",
    "df, y = hf.preprocess_data(df, classif)\n",
    "print(\" ✓ Data succefuly pre-prossesed \")\n",
    "\n",
    "#-------------------------------------------------------\n",
    "#                  Feature Selection\n",
    "# ------------------------------------------------------\n",
    "df = hf.feature_selection(df,'PCA',variance_threshold=0.95)\n",
    "\n",
    "#-------------------------------------------------------\n",
    "#           Split Data ( 70% train, 30% test )\n",
    "#-------------------------------------------------------\n",
    "X_train, X_test, y_train, y_test = hf.split_data(df,y,test_size=0.4)\n",
    "# Explore data shapes \n",
    "X_train.shape\n",
    "X_test.shape \n",
    "print(f'\\nShape of Data \\n Training Data = {X_train.shape}   | Test Data = {X_test.shape} \\n Training Labels = {y_train.shape}   |  Test_labels = {y_test.shape} \\n ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Model Selection and training\n",
    "\n",
    "   The user can choose between multiple models given below. The data is then trained using a gridsearch to find the best parameters for the given model from a set of parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 1 - Logistic Regression => lr \n",
      " 2 - SGD Classifier => sgd_clf \n",
      " 3 - AdaBoost Classifier => ab_clf \n",
      " 4 - SVM Classifier => svm   \n",
      " 5 - Random Forset Classifier => rf_clf \n",
      " 6 - k-Nearest Neighbors => knn\n"
     ]
    }
   ],
   "source": [
    "#-------------------------------------------\n",
    "#               Model Selection\n",
    "#-------------------------------------------\n",
    "print('\\n 1 - Logistic Regression => lr \\n 2 - SGD Classifier => sgd_clf \\n 3 - AdaBoost Classifier => ab_clf \\n 4 - SVM Classifier => svm   \\n 5 - Random Forset Classifier => rf_clf \\n 6 - k-Nearest Neighbors => knn' )\n",
    "model_name = input(\"Please Enter Name of the selected model : \")\n",
    "print(\"--------------------------------------------\")\n",
    "model,train_score = hf.train_model(model_name,X_train,y_train)\n",
    "print('Train Accuracy = ',train_score)\n",
    "print('Test Accuracy  = ',model.score(X_test, y_test))\n",
    "print('F1 Score = ', f1_score(y_test,model.predict(X_test),average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5af6db1fe6810fe648d3ea165c1ad2705eba3129b5b7b03805b160185b3319d3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
